{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! apt-get install unrar\n",
        "! unrar x /content/model.rarq\n",
        "! mkdir /content/new_imgs"
      ],
      "metadata": {
        "id": "rdPYYmrtVhPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51bd734-6b8c-429c-9526-fdf994c3f091"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:6.1.5-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n",
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "Cannot open /content/model.rarq\n",
            "No such file or directory\n",
            "No files to extract\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hwzp9midTx6J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from keras.models import load_model\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = {'Baked Potato': 0,\n",
        " 'Crispy Chicken': 1,\n",
        " 'Donut': 2,\n",
        " 'Fries': 3,\n",
        " 'Hot Dog': 4,\n",
        " 'Sandwich': 5,\n",
        " 'Taco': 6,\n",
        " 'Taquito': 7,\n",
        " 'apple_pie': 8,\n",
        " 'burger': 9,\n",
        " 'butter_naan': 10,\n",
        " 'chai': 11,\n",
        " 'chapati': 12,\n",
        " 'cheesecake': 13,\n",
        " 'chicken_curry': 14,\n",
        " 'chole_bhature': 15,\n",
        " 'dal_makhani': 16,\n",
        " 'fried_rice': 17,\n",
        " 'ice_cream': 18,\n",
        " 'idli': 19,\n",
        " 'jalebi': 20,\n",
        " 'kaathi_rolls': 21,\n",
        " 'kadai_paneer': 22,\n",
        " 'masala_dosa': 23,\n",
        " 'momos': 24,\n",
        " 'omelette': 25,\n",
        " 'pakode': 26,\n",
        " 'pav_bhaji': 27,\n",
        " 'pizza': 28,\n",
        " 'sushi': 29}"
      ],
      "metadata": {
        "id": "HC2vjiqyxP5-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Especifica el nombre del archivo comprimido que subiste\n",
        "archivo_comprimido = \"/content/best_model_tf.zip\"\n",
        "\n",
        "# Especifica la carpeta de destino para la extracción\n",
        "carpeta_destino = \"/content/model\"\n",
        "\n",
        "# Descomprime el archivo en la carpeta de destino\n",
        "with zipfile.ZipFile(archivo_comprimido, 'r') as zip_ref:\n",
        "    zip_ref.extractall(carpeta_destino)\n"
      ],
      "metadata": {
        "id": "VjNsmZKd1h6m"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta al directorio del modelo SavedModel\n",
        "model_dir = '/content/model/best_model_tf'\n",
        "\n",
        "# Cargar el modelo SavedModel\n",
        "loaded_model = tf.saved_model.load(model_dir)\n",
        "\n",
        "# Obtener una referencia a la función predict del modelo\n",
        "model_predict = loaded_model.signatures[\"serving_default\"]\n",
        "\n",
        "# Cargar la imagen nueva que deseas clasificar\n",
        "images_path = '/content/new_imgs'  # Reemplaza con la ruta de tu imagen\n",
        "image_path = os.listdir(images_path)\n",
        "\n",
        "for imgs_path in image_path:\n",
        "  image = Image.open(os.path.join(images_path, imgs_path))  # Abre la imagen utilizando Pillow\n",
        "\n",
        "  # Realiza el preprocesamiento necesario en la imagen\n",
        "  input_height, input_width = 224, 224\n",
        "  image = image.resize((input_width, input_height))\n",
        "  image = np.array(image, dtype=np.float32) / 255.0  # Convertir a float32 y normalizar\n",
        "\n",
        "  # Agregar una dimensión adicional para que coincida con el formato de entrada esperado\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "\n",
        "  # Realizar la inferencia en la imagen\n",
        "  output = model_predict(tf.constant(image))\n",
        "\n",
        "  # Las predicciones están en el diccionario 'output'\n",
        "  # Dependiendo del modelo, se podría acceder a las predicciones con output['nombre_del_tensor_de_salida']\n",
        "  # Por ejemplo, si el tensor de salida se llama 'output_tensor', se puede acceder a las predicciones con output['output_tensor']\n",
        "  predictions = output['dense_2']\n",
        "\n",
        "  # Ahora 'predictions' contiene las predicciones del modelo para la imagen\n",
        "  # Se puede convertir las predicciones en la clase predicha (índice de clase) utilizando np.argmax\n",
        "  predicted_class = np.argmax(predictions, axis=1)\n",
        "\n",
        "  # Imprimir la clase predicha\n",
        "  print(f'Clase predicha para {imgs_path}: {list(class_name)[predicted_class[0]]} ({predicted_class[0]})')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQgquqyfULxo",
        "outputId": "f3be97a9-7ebc-491b-c9b9-6b9af01e9468"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase predicha para applepie.jpg: ice_cream (18)\n",
            "Clase predicha para bakedpotato.jpg: Baked Potato (0)\n",
            "Clase predicha para sushi.jpg: momos (24)\n",
            "Clase predicha para friedrice.jpg: fried_rice (17)\n",
            "Clase predicha para donut.jpg: Donut (2)\n",
            "Clase predicha para fries.jpg: Fries (3)\n"
          ]
        }
      ]
    }
  ]
}